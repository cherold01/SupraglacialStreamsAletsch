{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Various helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "using LsqFit ## a package for least square fitting\n",
    "\"\"\"\n",
    "    fit_calibration(bucketsize, solution, calis...)\n",
    "\n",
    "Fits a line of best fit through the calibration data going through the origin.\n",
    "Returns the function of this line: `f(cond-cond_at_0) -> concentration`.\n",
    "\n",
    "Also prints the parameters values +/- 95% confidence intervals.\n",
    "\n",
    "Uses the package LsqFit: https://github.com/JuliaOpt/LsqFit.jl\n",
    "\"\"\"\n",
    "function fit_calibration(bucketsize, solution, calis...)\n",
    "    # subtract readout at zero concentration\n",
    "    for c in calis\n",
    "        @assert c[1,1]==0 \"First row needs to be zero reading!\"\n",
    "        c[:,2] .= c[:,2].-c[1,2]\n",
    "    end\n",
    "    # concatenate all calibrations\n",
    "    cali = vcat(calis...)\n",
    "    conc = ml_to_concentration(cali[:,1], solution, bucketsize)\n",
    "    delta_readout = cali[:,2]\n",
    "    # Fit line using https://github.com/JuliaOpt/LsqFit.jl\n",
    "    fn(delta_readout, p) = p[1]*delta_readout ## p[1]==a, p[2]==b\n",
    "    para_weights = [0.5] ## equal weights to parameters\n",
    "    fit = curve_fit(fn, delta_readout, conc, para_weights)\n",
    "    errors = margin_error(fit, 1-0.95)\n",
    "    println(\"\"\"\n",
    "    Estimated linear fit: f(delta_cond) = a*conc with\n",
    "     a = $(round(fit.param[1],sigdigits=3))±$(round(errors[1],sigdigits=3))\n",
    "    \"\"\")\n",
    "    return (delta_readout) -> fn(delta_readout, fit.param)\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit calibration for Stage-Discharge Relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "using LsqFit ## a package for least square fitting\n",
    "\"\"\"\n",
    "    fit_calibration(bucketsize, solution, calis...)\n",
    "\n",
    "Fits a line of best fit through the calibration data going through the origin.\n",
    "Returns the function of this line: `f(cond-cond_at_0) -> concentration`.\n",
    "\n",
    "Also prints the parameters values +/- 95% confidence intervals.\n",
    "\n",
    "Uses the package LsqFit: https://github.com/JuliaOpt/LsqFit.jl\n",
    "\"\"\"\n",
    "function fit_calibration_sd(calis...) #bucketsize and solution deleted\n",
    "    \"\"\"\n",
    "    # subtract readout at zero concentration\n",
    "    for c in calis\n",
    "        @assert c[1,1]==0 \"First row needs to be zero reading!\"\n",
    "        c[:,2] .= c[:,2].-c[1,2]\n",
    "    end\n",
    "    \"\"\"\n",
    "    # concatenate all calibrations\n",
    "    cali = vcat(calis...)\n",
    "    #conc = ml_to_concentration(cali[:,1], solution, bucketsize)\n",
    "    discharge = cali[:,1]\n",
    "    delta_readout = cali[:,2]\n",
    "    # Fit line using https://github.com/JuliaOpt/LsqFit.jl\n",
    "    fn(delta_readout, p) = p[1] .+ p[2]*delta_readout ## p[1]==a, p[2]==b\n",
    "    para_weights = [0.5,0.5] ## equal weights to parameters\n",
    "    fit = curve_fit(fn, delta_readout, discharge, para_weights)\n",
    "    #errors = margin_error(fit, 1-0.95)\n",
    "    println(\"\"\"\n",
    "    Estimated linear fit: Q(s) = a + b*discharge with\n",
    "     a = $(round(fit.param[1],sigdigits=3)), b = $(round(fit.param[2],sigdigits=3))\n",
    "    \"\"\")\n",
    "    return (delta_readout) -> fn(delta_readout, fit.param)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#linear relation q(s) \n",
    "# same as fit_calibration_sd but can handle uncertainties\n",
    "\n",
    "using LsqFit # a package for least square fitting\n",
    "using MonteCarloMeasurements, GLMakie\n",
    "\n",
    "\"\"\"\n",
    "    curve_fit_MCMeasurements(model, x, y, p0)\n",
    "\n",
    "Does LsqFit.curve_fit with MonteCarloMeasurements Vectors.  Same input as `curve_fit`.\n",
    "\"\"\"\n",
    "function curve_fit_MCMeasurements(model, x, y, p0)\n",
    "    if eltype(x)<:Particles && eltype(y)<:Particles\n",
    "        len = length(x[1].particles)\n",
    "        pout = [eltype(p0)[] for p in p0]\n",
    "        for i=1:len\n",
    "            p = curve_fit(model, [xx.particles[i] for xx in x], [yy.particles[i] for yy in y], p0)\n",
    "            @assert p.converged\n",
    "            for j=1:length(p0)\n",
    "                push!(pout[j], p.param[j])\n",
    "            end\n",
    "        end\n",
    "    elseif eltype(y)<:Particles\n",
    "        len = length(y[1].particles)\n",
    "        pout = [eltype(p0)[] for p in p0]\n",
    "        for i=1:len\n",
    "            p = curve_fit(model, x, [yy.particles[i] for yy in y], p0)\n",
    "            @assert p.converged \"$i\"\n",
    "            for j=1:length(p0)\n",
    "                push!(pout[j], p.param[j])\n",
    "            end\n",
    "        end\n",
    "    elseif eltype(x)<:Particles\n",
    "        len = length(x[1].particles)\n",
    "        pout = [eltype(p0)[] for p in p0]\n",
    "        for i=1:len\n",
    "            p = curve_fit(model, [xx.particles[i] for xx in x], y, p0)\n",
    "            @assert p.converged\n",
    "            for j=1:length(p0)\n",
    "                push!(pout[j], p.param[j])\n",
    "            end\n",
    "        end\n",
    "    else\n",
    "        error()\n",
    "    end\n",
    "    return [Particles(po) for po in pout]\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Keller sensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "read_WTW"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Dates\n",
    "using DelimitedFiles: readdlm, writedlm ## Date time handling; CSV file handling\n",
    "const g = 9.81\n",
    "const rhow = 1000.0\n",
    "\n",
    "\"\"\"\n",
    "         read_Keller(filename;\n",
    "                     presshead=\"P1\",\n",
    "                     condhead=\"ConRaw\",\n",
    "                     temphead=\"TOB1\",\n",
    "                     skipstart=8,\n",
    "                     )\n",
    "\n",
    "Reads a Keller pressure/CTD sensor.  However, you probably want to use\n",
    "- `read_Keller_DCX22_CTD`,\n",
    "- `read_Keller_DCX22` and\n",
    "- `read_Keller_DC22`\n",
    "\n",
    "Returns a dict with keys as appropriate:\n",
    "- :t [date-time stamp]\n",
    "- :cond [μS/cm]\n",
    "- :temp [C]\n",
    "- :press [m H2O]\n",
    "\"\"\"\n",
    "function read_Keller(filename;\n",
    "                     presshead=\"P1\",\n",
    "                     condhead=\"ConRaw\",\n",
    "                     temphead=\"TOB1\",\n",
    "                     skipstart=8,\n",
    "                     )\n",
    "    d,h = readdlm(filename, ';', skipstart=skipstart, header=true)\n",
    "    h = h[:] ## h is a 1x2 matrix, change to a vector\n",
    "\n",
    "    out = Dict{Symbol,Any}()\n",
    "    # find date-time rows\n",
    "    id, it = findfirst(h.==\"Date\"), findfirst(h.==\"Time\")\n",
    "    # time 12.08.2016 13:36:58\n",
    "    fmtd, fmtt = \"d/m/y\", \"H:M:S\"\n",
    "    out[:t] = [Date(dd, fmtd) + Time(tt, fmtt) for (dd,tt) in zip(d[:,id], d[:,it])]\n",
    "\n",
    "    for (head, key) in [(presshead, :press),\n",
    "                        (condhead, :cond),\n",
    "                        (temphead, :temp)]\n",
    "        i = findfirst(h.==head) ## see if there is one\n",
    "        tmp = Float64[]\n",
    "        if i!=nothing\n",
    "            out[key] = [s==\"\" ? missing :\n",
    "                        s isa AbstractString ? parse(Float64, replace(s, \",\"=>\".\")) : Float64(s) for s in d[:,i]]\n",
    "            # convert mS/cm to μS/cm\n",
    "            if key==:cond\n",
    "                out[:cond] = out[:cond].*1 #changed by Casi bc my data already is in uS/cm\n",
    "            end\n",
    "            # convert pressure from mbar to m H2O\n",
    "            if key==:press\n",
    "                out[:press] = out[:press]*1e2 /g/rhow\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # check lengths and remove all \"missing\"\n",
    "    l = length(out[:t])\n",
    "    topurge = []\n",
    "    for v in values(out)\n",
    "        @assert length(v)==l\n",
    "        append!(topurge, findall(v.===missing))\n",
    "    end\n",
    "    topurge = sort(unique(topurge))\n",
    "    for (k,v) in out\n",
    "        deleteat!(v, topurge)\n",
    "        if k!=:t\n",
    "            out[k] = Float64.(v) ## make the vector an\n",
    "        end\n",
    "    end\n",
    "    return out\n",
    "end\n",
    "\n",
    "read_Keller_DCX22_CTD(filename) = read_Keller(filename)\n",
    "read_Keller_DCX22(filename) = read_Keller(filename, error(\"Not implement yet\"))\n",
    "\n",
    "\"\"\"\n",
    "    cut_sensor_readout(sensor_readout, tinj, tend)\n",
    "\n",
    "Cuts the time series into individual tracer experiments.\n",
    "\"\"\"\n",
    "function cut_sensor_readout(sensor_readout, tinj, tend)\n",
    "\n",
    "    iinj = findfirst(sensor_readout[:t].>tinj)\n",
    "    iend = findfirst(sensor_readout[:t].>tend)\n",
    "    out = Dict()\n",
    "    if iinj===nothing || iend===nothing || iinj==iend\n",
    "        return out\n",
    "    else\n",
    "        iend = iend - 1\n",
    "    end\n",
    "    for (k,v) in sensor_readout\n",
    "        if v isa Vector\n",
    "            out[k] = v[iinj:iend]\n",
    "        else\n",
    "            out[k] = v\n",
    "        end\n",
    "    end\n",
    "    # add time in secs since injection\n",
    "    t = sensor_readout[:t]\n",
    "    tt = convert(Vector{Float64}, Dates.value.(t[iinj:iend]-t[iinj])/1000)\n",
    "    out[:tsec] = tt\n",
    "    return out\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "        read_WTW(filename)\n",
    "\n",
    "This function reads a file from the WTW conductivity sensor and\n",
    "returns:\n",
    "\n",
    "Dict with keys: :t [date-time stamp], :cond [μS/cm], :temp [C]\n",
    "\n",
    "Note, that the input file usually contains several traces.  Split them up with\n",
    "`split_conductivity_data`.\n",
    "\"\"\"\n",
    "function read_WTW(filename)\n",
    "    if !isfile(filename)\n",
    "        error(\"Filename $filename is not a file!\")\n",
    "    end\n",
    "    if !startswith(splitdir(filename)[2], \"AD\")\n",
    "        @warn(\"Read in a file starting with `AD`.  (The `AC` files use a comma for the decimal point.\")\n",
    "    end\n",
    "    d, head = readdlm(filename, ';', header=true)\n",
    "    out = Dict{Symbol,Any}() ## key has the be Symbol, value can be anything\n",
    "    # time 12.08.2016 13:36:58\n",
    "    fmt = \"d.m.y H:M:S\"\n",
    "    out[:t] = [DateTime(dd, fmt) for dd in d[:,4]]\n",
    "    # conductivity\n",
    "    out[:cond] = d[:,5]\n",
    "    units = d[:,6]\n",
    "    @assert all(units.==\"\\xb5S/cm\") \"Units not in μS/cm!\"\n",
    "    # temp\n",
    "    out[:temp] = d[:,8]\n",
    "\n",
    "    # purge any records which are simultaneous (not sure why this happens with the WTW)\n",
    "    purge = findall(diff(out[:t]).==Second(0))\n",
    "    for p in reverse(purge)\n",
    "        deleteat!(out[:t], p)\n",
    "        deleteat!(out[:cond],p)\n",
    "        deleteat!(out[:temp], p)\n",
    "    end\n",
    "\n",
    "    return out\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "read_Keller_air (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "function read_Keller_air(filename;\n",
    "                     presshead=\"P2\",\n",
    "                     condhead=\"ConRaw\",\n",
    "                     temphead=\"TOB2\",\n",
    "                     skipstart=8,\n",
    "                     )\n",
    "    d,h = readdlm(filename, ';', skipstart=skipstart, header=true)\n",
    "    h = h[:] ## h is a 1x2 matrix, change to a vector\n",
    "\n",
    "    out = Dict{Symbol,Any}()\n",
    "    # find date-time rows\n",
    "    id, it = findfirst(h.==\"Date\"), findfirst(h.==\"Time\")\n",
    "    # time 12.08.2016 13:36:58\n",
    "    fmtd, fmtt = \"d/m/y\", \"H:M:S\"\n",
    "    out[:t] = [Date(dd, fmtd) + Time(tt, fmtt) for (dd,tt) in zip(d[:,id], d[:,it])]\n",
    "\n",
    "    for (head, key) in [(presshead, :press),\n",
    "                        (condhead, :cond),\n",
    "                        (temphead, :temp)]\n",
    "        i = findfirst(h.==head) ## see if there is one\n",
    "        tmp = Float64[]\n",
    "        if i!=nothing\n",
    "            out[key] = [s==\"\" ? missing :\n",
    "                        s isa AbstractString ? parse(Float64, replace(s, \",\"=>\".\")) : Float64(s) for s in d[:,i]]\n",
    "            # convert mS/cm to μS/cm\n",
    "            if key==:cond\n",
    "                out[:cond] = out[:cond].*1 #changed by Casi bc my data already is in uS/cm\n",
    "            end\n",
    "            # convert pressure from mbar to m H2O\n",
    "            if key==:press\n",
    "                out[:press] = out[:press]*1e2 /g/rhow\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # check lengths and remove all \"missing\"\n",
    "    l = length(out[:t])\n",
    "    topurge = []\n",
    "    for v in values(out)\n",
    "        @assert length(v)==l\n",
    "        append!(topurge, findall(v.===missing))\n",
    "    end\n",
    "    topurge = sort(unique(topurge))\n",
    "    for (k,v) in out\n",
    "        deleteat!(v, topurge)\n",
    "        if k!=:t\n",
    "            out[k] = Float64.(v) ## make the vector an\n",
    "        end\n",
    "    end\n",
    "    return out\n",
    "end\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.5",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
