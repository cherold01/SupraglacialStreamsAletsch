{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions for salt-dilution notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Precompiling LsqFit [2fda8390-95c7-5789-9bda-21331edee243]\n",
      "└ @ Base loading.jl:1242\n"
     ]
    }
   ],
   "source": [
    "using LsqFit # a package for least square fitting\n",
    "\"\"\"\n",
    "    fit_calibration(bucketsize, solution, calis...)\n",
    "\n",
    "Fits a line of best fit through the calibration data going through the origin.  \n",
    "Returns the function of this line: `f(cond-cond_at_0) -> concentration`.\n",
    "\n",
    "Also prints the parameters values +/- 95% confidence intervals.\n",
    "\n",
    "Uses the package LsqFit: https://github.com/JuliaOpt/LsqFit.jl\n",
    "\"\"\"\n",
    "function fit_calibration(bucketsize, solution, calis...)\n",
    "    # subtract readout at zero concentration\n",
    "    for c in calis\n",
    "        @assert c[1,1]==0 \"First row needs to be zero reading!\"\n",
    "        c[:,2] .= c[:,2].-c[1,2]\n",
    "    end\n",
    "    # concatenate all calibrations\n",
    "    cali = vcat(calis...)\n",
    "    conc = ml_to_concentration(cali[:,1], solution, bucketsize)\n",
    "    delta_readout = cali[:,2]\n",
    "    # Fit line using https://github.com/JuliaOpt/LsqFit.jl\n",
    "    fn(delta_readout, p) = p[1]*delta_readout # p[1]==a, p[2]==b\n",
    "    para_weights = [0.5] # equal weights to parameters\n",
    "    fit = curve_fit(fn, delta_readout, conc, para_weights)\n",
    "    errors = margin_error(fit, 1-0.95)\n",
    "    println(\"\"\"\n",
    "    Estimated linear fit: f(delta_cond) = a*conc with\n",
    "     a = $(round(fit.param[1],sigdigits=3))±$(round(errors[1],sigdigits=3))\n",
    "    \"\"\")\n",
    "    return (delta_readout) -> fn(delta_readout, fit.param)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "read_Keller_DC22 (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Dates\n",
    "using DelimitedFiles: readdlm # Date time handling; CSV file handling\n",
    "\n",
    "# These will read files containing time series of a combination of the following sensors:\n",
    "# conductivity, pressure, temperature\n",
    "# The convention is to return a dict with keys as appropriate:\n",
    "# :t [date-time stamp], :cond [μS/cm], :temp [C], :press [m H2O]\n",
    "#\n",
    "# (Note, the funny \":\" in front of the name makes a special kind of string, a so-called Symbol)\n",
    "\n",
    "\"\"\"\n",
    "    read_WTW(filename)\n",
    "\n",
    "This function reads a file from the WTW conductivity sensor and\n",
    "returns:\n",
    "\n",
    "Dict with keys: :t [date-time stamp], :cond [μS/cm], :temp [C]\n",
    "\n",
    "Note, that the input file usually contains several traces.  Split them up with \n",
    "`split_conductivity_data`.\n",
    "\"\"\"\n",
    "function read_WTW(filename)\n",
    "    if !isfile(filename)\n",
    "        error(\"Filename $filename is not a file!\")\n",
    "    end\n",
    "    if !startswith(splitdir(filename)[2], \"AD\")\n",
    "        warn(\"Read in a file starting with `AD`.  (The `AC` files use a comma for the decimal point.\")\n",
    "    end\n",
    "    d, head = readdlm(filename, ';', header=true)\n",
    "    out = Dict{Symbol,Any}() # key has the be Symbol, value can be anything\n",
    "    # time 12.08.2016 13:36:58\n",
    "    fmt = \"d.m.y H:M:S\"\n",
    "    out[:t] = [DateTime(dd, fmt) for dd in d[:,4]]\n",
    "    # conductivity\n",
    "    out[:cond] = d[:,5]\n",
    "    units = d[:,6]\n",
    "    @assert all(units.==\"\\xb5S/cm\") \"Units not in μS/cm!\"\n",
    "    # temp\n",
    "    out[:temp] = d[:,8]\n",
    "    \n",
    "    # purge any records which are simultaneous (not sure why this happens with the WTW)\n",
    "    purge = findall(diff(out[:t]).==Second(0))\n",
    "    for p in reverse(purge)\n",
    "        deleteat!(out[:t], p)\n",
    "        deleteat!(out[:cond],p)\n",
    "        deleteat!(out[:temp], p)\n",
    "    end\n",
    "\n",
    "    return out\n",
    "end\n",
    "\n",
    "    using DelimitedFiles, Dates\n",
    "\n",
    "const g = 9.81\n",
    "const rhow = 1000.0\n",
    "\n",
    "\"\"\"\n",
    "         read_Keller(filename;\n",
    "                     presshead=\"P1\",\n",
    "                     condhead=\"ConRaw\",\n",
    "                     temphead=\"TOB1\",\n",
    "                     skipstart=8,\n",
    "                     )\n",
    "\n",
    "Reads a Keller pressure/CTD sensor.  However, you probably want to use\n",
    "- `read_Keller_DCX22_CTD`, \n",
    "- `read_Keller_DCX22` and \n",
    "- `read_Keller_DC22` \n",
    "\n",
    "Returns a dict with keys as appropriate:\n",
    "- :t [date-time stamp]\n",
    "- :cond [μS/cm]\n",
    "- :temp [C]\n",
    "- :press [m H2O]\n",
    "\"\"\"\n",
    "function read_Keller(filename;\n",
    "                     presshead=\"P1\",\n",
    "                     condhead=\"ConRaw\",\n",
    "                     temphead=\"TOB1\",\n",
    "                     skipstart=8,\n",
    "                     )\n",
    "    d,h = readdlm(filename, ';', skipstart=skipstart, header=true)\n",
    "    h = h[:] # h is a 1x2 matrix, change to a vector\n",
    "\n",
    "    out = Dict{Symbol,Any}()\n",
    "    # find date-time rows\n",
    "    id, it = findfirst(h.==\"Date\"), findfirst(h.==\"Time\")\n",
    "    # time 12.08.2016 13:36:58\n",
    "    fmtd, fmtt = \"d/m/y\", \"H:M:S\"\n",
    "    out[:t] = [Date(dd, fmtd) + Time(tt, fmtt) for (dd,tt) in zip(d[:,id], d[:,it])]\n",
    "\n",
    "    #\n",
    "    for (head, key) in [(presshead, :press),\n",
    "                        (condhead, :cond),\n",
    "                        (temphead, :temp)]\n",
    "        i = findfirst(h.==head) # see if there is one\n",
    "        tmp = Float64[]\n",
    "        if i!=nothing\n",
    "            out[key] = [s==\"\" ? missing :\n",
    "                        s isa AbstractString ? parse(Float64, replace(s, \",\"=>\".\")) : Float64(s) for s in d[:,i]]\n",
    "            # convert mS/cm to μS/cm\n",
    "            if key==:cond\n",
    "                out[:cond] = out[:cond].*1000\n",
    "            end\n",
    "            # convert pressure from mbar to m H2O\n",
    "            if key==:press\n",
    "                out[:press] = out[:press]*1e2 /g/rhow\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # check lengths and remove all \"missing\"\n",
    "    l = length(out[:t])\n",
    "    topurge = []\n",
    "    for v in values(out)\n",
    "        @assert length(v)==l\n",
    "        append!(topurge, findall(v.===missing))\n",
    "    end\n",
    "    topurge = sort(unique(topurge))\n",
    "    for (k,v) in out\n",
    "        deleteat!(v, topurge)\n",
    "        if k!=:t\n",
    "            out[k] = Float64.(v) # make the vector an\n",
    "        end\n",
    "    end\n",
    "    return out\n",
    "end\n",
    "\n",
    "read_Keller_DCX22_CTD(filename) = read_Keller(filename)\n",
    "read_Keller_DCX22(filename) = read_Keller(filename, error(\"Not implement yet\"))\n",
    "read_Keller_DC22(filename) = read_Keller(filename,\n",
    "                                         presshead=\"p1/mbar\",\n",
    "                                         temphead=\"t1/\\xb0C\",\n",
    "                                         skipstart=24\n",
    "                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    split_conductivity_data_timegap(outdict, timegap=5.0, mincond=0.5, maxtemp=2)\n",
    "\n",
    "Splits up the time series returned by `read_conductivity_data` into individual\n",
    "traces, mostly by using that there is a big time-gap in the record.\n",
    "\n",
    "First the datapoints which have `outdict[:cond]<mincond` or `outdict[:temp]>maxtemp` are deleted.\n",
    "Then, the split is done where the time-gap is bigger than `timegap` seconds.\n",
    "\n",
    "The output is a list of traces:\n",
    "\n",
    "`traces = [trace1, trace2, etc]`\n",
    "\n",
    "where `trace1` contains the time series with `:t` in seconds after recoding started, `:tstart` is \n",
    "the date-time of the start of the recording.  You should also add the injection `:mass` to each trace \n",
    "manually.\n",
    "\n",
    "Thus to access the times of the second trace do `traces[2][:t]`, and to get the corresponding\n",
    "conductivity readout `traces[2][:cond]`.\n",
    "\"\"\"\n",
    "function split_conductivity_data_timegap(out; timegap=5.0, mincond=0.0, maxtemp=2, minpeak=6, minduration=60)\n",
    "    # delete where cond<mincond and temp>maxtemp\n",
    "    out = deepcopy(out)\n",
    "    tokeep = (out[:cond].>mincond) .& (out[:temp].<maxtemp)\n",
    "    for (k,v) in out\n",
    "        out[k] = v[tokeep]\n",
    "    end\n",
    "\n",
    "    t = out[:t]\n",
    "    cond = out[:cond]   \n",
    "\n",
    "    # split it up according to time gaps\n",
    "    splits_at = findall(diff(t).>Second(timegap))\n",
    "    push!(splits_at, length(t))\n",
    "    traces = []\n",
    "    i = 1\n",
    "    for sp in splits_at\n",
    "        tt = convert(Vector{Float64}, Dates.value.(t[i:sp]-t[i])/1000)\n",
    "        dt = t[i+1]-t[i]\n",
    "        if !all(diff(t[i:sp]).==dt) \n",
    "            #@warn \"Logging intervals are not evenly spaced!\"\n",
    "        end\n",
    "        tmp = Dict{Symbol,Any}()\n",
    "        tmp[:t] = tt\n",
    "        if tt[end]-tt[1]<minduration\n",
    "            continue\n",
    "        end\n",
    "        tmp[:tstart] = t[i]\n",
    "        tmp[:cond] = cond[i:sp]\n",
    "        if maximum(tmp[:cond])<minpeak\n",
    "            continue\n",
    "        end\n",
    "        if haskey(out, :temp)\n",
    "            tmp[:temp] = out[:temp][i:sp]\n",
    "        end\n",
    "        if haskey(out, :press)\n",
    "            tmp[:press] = out[:press][i:sp]\n",
    "        end\n",
    "        push!(traces, tmp)\n",
    "        i = sp+1\n",
    "    end\n",
    "    \n",
    "    return traces\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "     split_conductivity_data(out;\n",
    "                             slice_cond=2.5,  # peaks are selected where cond is above this value\n",
    "                             slice_padding_start=20, # add a padding of in front of detected peak\n",
    "                             slice_padding_end=3*60, # add a padding of in back of detected peak\n",
    "                             mincond=0.5, maxtemp=3, # also drop points which have conductivity below mincond and above maxtemp\n",
    "                             smooth_window=10) # smoothing window used in peak detection\n",
    "\n",
    "Splits up the time series returned by `read_conductivity_data` into individual\n",
    "traces, mostly by heuristics around where peaks are.  A bit hit and miss.\n",
    "\n",
    "The output is a list of traces:\n",
    "\n",
    "`traces = [trace1, trace2, etc]`\n",
    "\n",
    "where `trace1` contains the time series with `:t` in seconds after recoding started, `:tstart` is\n",
    "the date-time of the start of the recording.  You should also add the injection `:mass` to each trace\n",
    "manually.\n",
    "\n",
    "Thus to access the times of the second trace do `traces[2][:t]`, and to get the corresponding\n",
    "conductivity readout `traces[2][:cond]`.\n",
    "\"\"\"\n",
    "function split_conductivity_data(out;\n",
    "                                 mincond=0.5, maxtemp=3,\n",
    "                                 slice_cond=2.5,\n",
    "                                 slice_padding_start=20,\n",
    "                                 slice_padding_end=3*60,\n",
    "                                 smooth_window=10)\n",
    "    out = deepcopy(out)\n",
    "\n",
    "    # smooth cond with running mean\n",
    "    cond = out[:cond]\n",
    "    t = out[:t]\n",
    "    condsmooth = zeros(length(cond))\n",
    "    for i=1:length(t)\n",
    "        ## running mean\n",
    "        tmp = 0.0\n",
    "        n = 0\n",
    "        for j=max(1,i-smooth_window):min(i+smooth_window, length(t))\n",
    "            tmp += cond[j]\n",
    "            n += 1\n",
    "        end\n",
    "        condsmooth[i] = tmp/n\n",
    "\n",
    "        # ## median\n",
    "        # condsmooth[i] = median(cond[max(1,i-smooth_window):min(i+smooth_window, length(t))])\n",
    "    end\n",
    "\n",
    "    # locate peaks with slice_cond and cut, also cut if time-gap bigger than timegap\n",
    "    inds = []\n",
    "\n",
    "    tokeep = condsmooth.>slice_cond\n",
    "    # add +/- slice_inds\n",
    "    s = 1\n",
    "    while true\n",
    "        s = findnext(tokeep, s)\n",
    "        if s==nothing\n",
    "            break\n",
    "        end\n",
    "        e = findnext(.!tokeep, s)\n",
    "        push!(inds, max(1, s-slice_padding_start):min(e+slice_padding_end, length(tokeep)))\n",
    "        s = e+1\n",
    "        if s>length(tokeep)\n",
    "            break\n",
    "        end\n",
    "    end\n",
    "\n",
    "    traces = []\n",
    "    i = 1\n",
    "    for ind in inds\n",
    "        tt = convert(Vector{Float64}, Dates.value.(t[ind]-t[ind[1]])/1000)\n",
    "        tmp = Dict{Symbol,Any}()\n",
    "\n",
    "        # delete where cond<mincond and temp>maxtemp\n",
    "        tokeep = (out[:cond][ind].>mincond) .& (out[:temp][ind].<maxtemp)\n",
    "\n",
    "        tmp[:t] = tt[tokeep]\n",
    "        tmp[:tstart] = t[ind][tokeep][1]\n",
    "        tmp[:cond] = cond[ind][tokeep]\n",
    "        tmp[:condsmooth] = condsmooth[ind][tokeep]\n",
    "        push!(traces, tmp)\n",
    "    end\n",
    "    return traces\n",
    "end\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.2.0",
   "language": "julia",
   "name": "julia-1.2"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
